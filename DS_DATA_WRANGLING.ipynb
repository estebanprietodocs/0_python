{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __DATA WRANGLING__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Pandas_Cheat_Sheet_2.pdf\n",
    "CSV\n",
    "IMPORTAR SOLO UNA PARTE DEL DATA FRAME\n",
    "READING MULTIPLES FILES WITH LIST COMPRENHENTION\n",
    "READING MULTIPLES FILES WITH GLOBING\n",
    "LOADING DATA FROM THE WEB IN CHUNKS\n",
    "SQL\n",
    "EXCEL\n",
    "WEB\n",
    "JSON - CREAR UN DATAFRAME VACIO Y CARGARLO CON DATA\n",
    "API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_cases</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38928341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38928341.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_cases  population\n",
       "0          0.0  38928341.0\n",
       "1          0.0  38928341.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### idem excel, json, html, sql\n",
    "import pandas as pd\n",
    "#input\n",
    "cols = ['total_cases', 'population']\n",
    "data = pd.read_csv(r'C:\\Users\\Mumes\\Desktop\\owid-covid-data.csv', nrows = 2, skiprows = lambda x: x in [1, 2], usecols = cols)\n",
    "data\n",
    "\n",
    "# nrows > para decir cuantos filas queremos importar\n",
    "# skiprows = para que no considera las primeras 2 filas. usamos lambda porque sino elimina el header\n",
    "# usecols > creamos una lista para levantar solo esas columnas. VER próxima sección, es mas simple\n",
    "# dtype > especificamos que tipo de data type queremos para esa columna\n",
    "# podemos especificar como clasificar errores\n",
    "\n",
    "#output\n",
    "#data.to_csv(r'C:\\Users\\Mumes\\Desktop\\output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTAR SOLO UNA PARTE DEL DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  continent     location\n",
       "0      Asia  Afghanistan\n",
       "1      Asia  Afghanistan"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(r'C:\\Users\\Mumes\\Desktop\\owid-covid-data.csv')[['continent', 'location']]\n",
    "df.columns # para consultar las cols del df\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READING MULTIPLES FILES WITH LIST COMPRENHENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52268, 34)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filenames= [r'C:\\Users\\Mumes\\Desktop\\owid-covid-data1.csv', r'C:\\Users\\Mumes\\Desktop\\owid-covid-data2.csv']\n",
    "dfs = [pd.read_csv(f) for f in filenames]\n",
    "df = pd.concat(dfs, axis='rows') \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### READING MULTIPLES FILES WITH GLOBBING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52268, 34)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "filenames = glob (r'C:\\Users\\Mumes\\Desktop\\owid-covid-data?.csv') #pattern >'path?.csv' for any single character \n",
    "dfs =  [pd.read_csv(f) for f in filenames]\n",
    "df = pd.concat(dfs, axis='rows') \n",
    "df.shape\n",
    "\n",
    "#pattern >'path*.csv' for any single file\n",
    "#pattern >'path?.csv' for any single character "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOADING DATA FROM THE WEB IN CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30115.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import libraries\n",
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://covid.ourworldindata.org/data/owid-covid-data.csv'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, r'C:\\Users\\Mumes\\Desktop\\owid-covid-data.csv')\n",
    "\n",
    "#loading data in chunks de 20 filas, solo para los 200 primeros registros\n",
    "result = []\n",
    "for chunk in pd.read_csv(r'C:\\Users\\Mumes\\Desktop\\owid-covid-data.csv',nrows=200, chunksize = 20):\n",
    "    result.append(sum(chunk['new_cases']))\n",
    "total = sum(result)\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import sql database\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "miConexion = mysql.connector.connect( host='localhost', user= 'root', passwd='mysqlpass', db='trabajadores' )\n",
    "cur = miConexion.cursor()\n",
    "cur.execute( \"SELECT * FROM employees\" )\n",
    "result = cur.fetchall() #fetchall busca todas las filas.\n",
    "sequence = cur.column_names\n",
    "miConexion.close()\n",
    "#convert to dataframe\n",
    "base_sql = pd.DataFrame (result, columns = sequence)\n",
    "base_sql.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create an engine to connect to a database > dialect+driver://username:password@host:port/database\n",
    "#from sqlalchemy import create_engine\n",
    "#engine = create_engine('mysql://root:mysqlpass@localhost:3306/trabajadores',  pool_recycle=3600)\n",
    "#table_names = engine.table_names()\n",
    "#table_names\n",
    "#OPERATIONAL ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pandas y sql\n",
    "#import pandas as pd\n",
    "#from sqlalchemy import create_engine\n",
    "#engine = create_engine('mysql://root:mysqlpass@localhost:3306/trabajadores')\n",
    "#df_sql = pd.read_sql_query(\"SELECT * FROM employees\", engine)\n",
    "#OPERATIONAL ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXCEL > ARMAMOS TABLA CON COL NOMBRE DE SOLAPA Y EXPORTAMOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pd.read_excel ()\n",
    "# usecols > ‘A:L, P:S’  > para que solo levante ese rango de columnas\n",
    "# multiple work sheets\n",
    "    #sheet_name  > para especificar la o las hojas que queremos (con numero o nombre, o lista)\n",
    "    #sheet_name = None > levanta todas las hojas del workbook\n",
    "#parse_dates> acepta una lista de columnas para designar como datetime\n",
    "#pd.to_datetime si no funciona lo anterior, despues que hayamos importado el archivo\n",
    "\n",
    "#PARA CONVERTIR A DATAFRAME CUANDO TODAS LAS HOJAS SON IGUALES\n",
    "# import workbook con multiples hojas (sheet_name = None > levanta todas las hojas del workbook)\n",
    "import pandas as pd\n",
    "multiples_hojas = pd.read_excel(r'C:\\Users\\Mumes\\Desktop\\groupby_location.xlsx', sheet_name = None, usecols ='A:E')\n",
    "#convertimos todas las hojas en un unico df. las hojas deben ser iguales ( mismas columnas)\n",
    "all_sheets = pd.DataFrame() #df vacio\n",
    "for sheet_name, frame in multiples_hojas.items():\n",
    "    frame['Hoja'] = sheet_name #agregamos una columna para distinguir la sheet de proveniencia\n",
    "    all_sheets = all_sheets.append (frame) #unificamos\n",
    "all_sheets.head(2)\n",
    "# exportamos a excel\n",
    "all_sheets.to_excel(r'C:\\Users\\Mumes\\Desktop\\all_sheets.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  WEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.994</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density   pH  sulphates  \\\n",
       "0                 45.0                 170.0    1.001  3.0       0.45   \n",
       "1                 14.0                 132.0    0.994  3.3       0.49   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "\n",
    "#> tambien podemos usar requests  library > send and get data from websites\n",
    "\n",
    "# Assign url of file: url\n",
    "#url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "\n",
    "# Save file locally\n",
    "#urlretrieve(url, r'C:\\Users\\Mumes\\Desktop\\wine_white.csv')\n",
    "\n",
    "wine_white = pd.read_csv(r'C:\\Users\\Mumes\\Desktop\\wine_white.csv', sep = ';')\n",
    "wine_white.head(2)\n",
    "\n",
    "#tambien podemos usar las librerias requests y beautiful soup para trabajar con html\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON  -  CREAR UN DATAFRAME VACIO Y CARGARLO CON DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  The Social Network\n",
      "Year:  2010\n",
      "Rated:  PG-13\n",
      "Released:  01 Oct 2010\n",
      "Runtime:  120 min\n",
      "Genre:  Biography, Drama\n",
      "Director:  David Fincher\n",
      "Writer:  Aaron Sorkin (screenplay), Ben Mezrich (book)\n",
      "Actors:  Jesse Eisenberg, Rooney Mara, Bryan Barter, Dustin Fitzsimons\n",
      "Plot:  As Harvard student Mark Zuckerberg creates the social networking site that would become known as Facebook, he is sued by the twins who claimed he stole their idea, and by the co-founder who was later squeezed out of the business.\n",
      "Language:  English, French\n",
      "Country:  USA\n",
      "Awards:  Won 3 Oscars. Another 171 wins & 183 nominations.\n",
      "Poster:  https://m.media-amazon.com/images/M/MV5BOGUyZDUxZjEtMmIzMC00MzlmLTg4MGItZWJmMzBhZjE0Mjc1XkEyXkFqcGdeQXVyMTMxODk2OTU@._V1_SX300.jpg\n",
      "Ratings:  [{'Source': 'Internet Movie Database', 'Value': '7.7/10'}, {'Source': 'Rotten Tomatoes', 'Value': '96%'}, {'Source': 'Metacritic', 'Value': '95/100'}]\n",
      "Metascore:  95\n",
      "imdbRating:  7.7\n",
      "imdbVotes:  603,038\n",
      "imdbID:  tt1285016\n",
      "Type:  movie\n",
      "DVD:  11 Jan 2011\n",
      "BoxOffice:  $96,400,000\n",
      "Production:  Columbia Pictures\n",
      "Website:  N/A\n",
      "Response:  True\n"
     ]
    }
   ],
   "source": [
    "#GENERALMENTE, PRIMERO NOS DEBERIAMOS AUTENTICAR EN LA PLATAFORMA DE LA API\n",
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Assign URL to variable: url API\n",
    "url = 'http://www.omdbapi.com/?apikey=72bc447a&t=social+network'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Decode the JSON data into a dictionary: json_data\n",
    "json_data = r.json()\n",
    "\n",
    "# Print each key-value pair in json_data\n",
    "for k in json_data.keys():\n",
    "    print(k + ': ', json_data[k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
